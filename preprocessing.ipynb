{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from keras_tuner import RandomSearch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# za 1 razem pobrac\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.csv', header=None, names=['sentiment', 'id', 'date', 'query', 'user', 'text'], encoding='ISO-8859-1')\n",
    "df = df.drop(columns=['query', 'id', 'user', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/13/vypvgv0x0n13zkc7gg4wg7hr0000gn/T/ipykernel_4200/1493389583.py:4: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette=\"viridis\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Number of Sentiment Classes\")\n",
    "plt.xlabel(\"Sentiment Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                0  is upset that he can't update his Facebook by ...\n",
       "2                0  @Kenichan I dived many times for the ball. Man...\n",
       "3                0    my whole body feels itchy and like its on fire \n",
       "4                0  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          4  Just woke up. Having no school is the best fee...\n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtags(text):\n",
    "    return len(re.findall(r'#', text))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove numbers (optional: uncomment if needed)\n",
    "    # text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Reconstruct the text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['hashtag_count'] = df['text'].apply(count_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>0</td>\n",
       "      <td>woke school best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>0</td>\n",
       "      <td>thewdbcom cool hear old walt interview â</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>0</td>\n",
       "      <td>ready mojo makeover ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>happy 38th birthday boo alll time tupac amaru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>1</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "0                0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1                0  is upset that he can't update his Facebook by ...   \n",
       "2                0  @Kenichan I dived many times for the ball. Man...   \n",
       "3                0    my whole body feels itchy and like its on fire    \n",
       "4                0  @nationwideclass no, it's not behaving at all....   \n",
       "...            ...                                                ...   \n",
       "1599995          4  Just woke up. Having no school is the best fee...   \n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "         hashtag_count                                       cleaned_text  \n",
       "0                    0  awww thats bummer shoulda got david carr third...  \n",
       "1                    0  upset cant update facebook texting might cry r...  \n",
       "2                    0  dived many time ball managed save 50 rest go b...  \n",
       "3                    0                    whole body feel itchy like fire  \n",
       "4                    0                           behaving im mad cant see  \n",
       "...                ...                                                ...  \n",
       "1599995              0                      woke school best feeling ever  \n",
       "1599996              0           thewdbcom cool hear old walt interview â  \n",
       "1599997              0                     ready mojo makeover ask detail  \n",
       "1599998              0  happy 38th birthday boo alll time tupac amaru ...  \n",
       "1599999              1                                              happy  \n",
       "\n",
       "[1600000 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=10000\n",
    "max_length = 20\n",
    "\n",
    "tokenizer = Tokenizer(num_words)\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "X_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "y_binary = [1 if label == 4 else 0 for label in df['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, K.floatx())  # Ensure y_true is cast to float\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, K.floatx())  # Ensure y_true is cast to float\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 17ms/step - accuracy: 0.7860 - f1_m: 15.6914 - loss: 0.4530 - precision_m: 15.9369 - recall_m: 15.7380 - val_accuracy: 0.8167 - val_f1_m: 15.6549 - val_loss: 0.4002 - val_precision_m: 16.0506 - val_recall_m: 15.4611\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8166 - f1_m: 15.6387 - loss: 0.4001 - precision_m: 16.0262 - recall_m: 15.4477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, Accuracy: [0.40018314123153687, 0.8166593909263611, 15.654923439025879, 16.050600051879883, 15.461099624633789]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_padded, y_binary, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "y_val = np.array(y_val, dtype=np.int32)\n",
    "\n",
    "embedding_dim = 128\n",
    "\n",
    "# Budowa modelu LSTM\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=embedding_dim),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "results = model.evaluate(X_val, y_val)\n",
    "print(\"Loss, Accuracy:\", results)\n",
    "\n",
    "model.save(\"models/lstm_sentiment_binary_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train[:1000]\n",
    "y_train_subset = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from random_search_lstm/lstm_tuning/tuner0.json\n",
      "Najlepsze hiperparametry:\n",
      "Liczba jednostek LSTM: 32\n",
      "Współczynnik dropout: 0.2\n",
      "Liczba jednostek Dense: 80\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=num_words, output_dim=hp.Choice('embedding_dim', [64, 128, 256])),\n",
    "        LSTM(units=hp.Int('lstm_units', min_value=32, max_value=128, step=32), return_sequences=False),\n",
    "        Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)),\n",
    "        Dense(units=hp.Int('dense_units', min_value=16, max_value=128, step=16), activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', f1_m, precision_m, recall_m]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Random Search\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Liczba prób Random Search\n",
    "    executions_per_trial=1,\n",
    "    directory='random_search_lstm',\n",
    "    project_name='lstm_tuning'\n",
    ")\n",
    "# Dane wejściowe do Random Search\n",
    "tuner.search(\n",
    "    X_train_subset, y_train_subset,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=tuner.oracle.hyperparameters.Choice('batch_size', [16, 32, 64])\n",
    ")\n",
    "\n",
    "# Najlepsze hiperparametry\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Najlepsze hiperparametry:\")\n",
    "print(f\"Liczba jednostek LSTM: {best_hps.get('lstm_units')}\")\n",
    "print(f\"Współczynnik dropout: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Liczba jednostek Dense: {best_hps.get('dense_units')}\")\n",
    "# print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 8ms/step - accuracy: 0.7775 - f1_m: 15.6420 - loss: 0.4652 - precision_m: 15.9998 - recall_m: 15.5870 - val_accuracy: 0.8097 - val_f1_m: 15.7564 - val_loss: 0.4168 - val_precision_m: 16.0506 - val_recall_m: 15.6621\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.8103 - f1_m: 15.7579 - loss: 0.4160 - precision_m: 16.0262 - recall_m: 15.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, Accuracy: [0.4167647063732147, 0.8096906542778015, 15.756443977355957, 16.050600051879883, 15.662099838256836]\n"
     ]
    }
   ],
   "source": [
    "# Budowa modelu CNN\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=embedding_dim),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dropout(0.5), \n",
    "    Dense(32, activation='relu'), \n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
    "\n",
    "# Trenowanie modelu\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Ewaluacja modelu\n",
    "results = model.evaluate(X_val, y_val)\n",
    "print(\"Loss, Accuracy:\", results)\n",
    "\n",
    "# Zapis modelu\n",
    "model.save(\"models/cnn_sentiment_binary_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from random_search_cnn/cnn_tuning/tuner0.json\n",
      "Najlepsze hiperparametry:\n",
      "Liczba filtrów: 192\n",
      "Rozmiar kernela: 3\n",
      "Współczynnik dropout: 0.4\n",
      "Liczba jednostek Dense: 112\n"
     ]
    }
   ],
   "source": [
    "# Funkcja budowy modelu CNN\n",
    "def build_cnn_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=num_words, output_dim=hp.Choice('embedding_dim', [64, 128, 256])),\n",
    "        Conv1D(\n",
    "            filters=hp.Int('filters', min_value=64, max_value=256, step=64),\n",
    "            kernel_size=hp.Choice('kernel_size', [3, 5, 7]),\n",
    "            activation='relu'\n",
    "        ),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)),\n",
    "        Dense(units=hp.Int('dense_units', min_value=16, max_value=128, step=16), activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', f1_m, precision_m, recall_m]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Random Search\n",
    "tuner_cnn = RandomSearch(\n",
    "    build_cnn_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Liczba prób Random Search\n",
    "    executions_per_trial=1,\n",
    "    directory='random_search_cnn',\n",
    "    project_name='cnn_tuning'\n",
    ")\n",
    "\n",
    "# Dane wejściowe do Random Search\n",
    "tuner_cnn.search(\n",
    "    X_train_subset, y_train_subset,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=tuner.oracle.hyperparameters.Choice('batch_size', [16, 32, 64])\n",
    ")\n",
    "\n",
    "# Najlepsze hiperparametry\n",
    "best_hps_cnn = tuner_cnn.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Najlepsze hiperparametry:\")\n",
    "print(f\"Liczba filtrów: {best_hps_cnn.get('filters')}\")\n",
    "print(f\"Rozmiar kernela: {best_hps_cnn.get('kernel_size')}\")\n",
    "print(f\"Współczynnik dropout: {best_hps_cnn.get('dropout_rate')}\")\n",
    "print(f\"Liczba jednostek Dense: {best_hps_cnn.get('dense_units')}\")\n",
    "#print(f\"Batch size: {best_hps_cnn.get('batch_size')}\")\n",
    "#print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m956s\u001b[0m 24ms/step - accuracy: 0.7807 - f1_m: 15.7833 - loss: 0.4531 - precision_m: 15.9718 - recall_m: 16.0133 - val_accuracy: 0.8167 - val_f1_m: 15.5264 - val_loss: 0.4014 - val_precision_m: 16.0506 - val_recall_m: 15.2146\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.8163 - f1_m: 15.5212 - loss: 0.4008 - precision_m: 16.0262 - recall_m: 15.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, Accuracy: [0.40138351917266846, 0.8166687488555908, 15.526445388793945, 16.050600051879883, 15.214599609375]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "\n",
    "# Budowa modelu GRU\n",
    "model_gru = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=embedding_dim),  # Warstwa osadzeń\n",
    "    GRU(128, return_sequences=False),  # Warstwa GRU, 128 jednostek\n",
    "    Dropout(0.5),  # Regularizacja\n",
    "    Dense(32, activation='relu'),  # Warstwa ukryta\n",
    "    Dense(1, activation='sigmoid')  # Warstwa wyjściowa\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
    "\n",
    "# Trenowanie modelu\n",
    "history_gru = model_gru.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1,  # Liczba epok\n",
    "    batch_size=32  # Rozmiar wsadu\n",
    ")\n",
    "\n",
    "# Ewaluacja modelu\n",
    "results_gru = model_gru.evaluate(X_val, y_val)\n",
    "print(\"Loss, Accuracy:\", results_gru)\n",
    "\n",
    "# Zapis modelu\n",
    "model_gru.save(\"models/gru_sentiment_binary_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from random_search_gru/gru_tuning/tuner0.json\n",
      "Najlepsze hiperparametry:\n",
      "Wymiary osadzeń: 256\n",
      "Liczba jednostek GRU: 64\n",
      "Współczynnik dropout: 0.2\n",
      "Liczba jednostek Dense: 64\n"
     ]
    }
   ],
   "source": [
    "def build_gru_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(\n",
    "            input_dim=num_words, \n",
    "            output_dim=hp.Choice('embedding_dim', [64, 128, 256])  # Testowane wymiary osadzeń\n",
    "        ),\n",
    "        GRU(\n",
    "            units=hp.Int('gru_units', min_value=64, max_value=256, step=64),  # Liczba jednostek GRU\n",
    "            return_sequences=False\n",
    "        ),\n",
    "        Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)),  # Współczynnik Dropout\n",
    "        Dense(\n",
    "            units=hp.Int('dense_units', min_value=16, max_value=128, step=16), \n",
    "            activation='relu'\n",
    "        ),\n",
    "        Dense(1, activation='sigmoid')  # Warstwa wyjściowa\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',  # Testowane learning rates\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', f1_m, precision_m, recall_m]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Random Search\n",
    "tuner_gru = RandomSearch(\n",
    "    build_gru_model,\n",
    "    objective='val_accuracy',  # Cel optymalizacji\n",
    "    max_trials=10,  # Liczba prób Random Search\n",
    "    executions_per_trial=1,  # Liczba wykonania na próbę\n",
    "    directory='random_search_gru',\n",
    "    project_name='gru_tuning'\n",
    ")\n",
    "\n",
    "# Przeprowadzenie wyszukiwania\n",
    "tuner_gru.search(\n",
    "    X_train_subset, y_train_subset,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=tuner.oracle.hyperparameters.Choice('batch_size', [16, 32, 64])  # Testowane rozmiary wsadów\n",
    ")\n",
    "\n",
    "# Pobranie najlepszych hiperparametrów\n",
    "best_hps_gru = tuner_gru.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Najlepsze hiperparametry:\")\n",
    "print(f\"Wymiary osadzeń: {best_hps_gru.get('embedding_dim')}\")\n",
    "print(f\"Liczba jednostek GRU: {best_hps_gru.get('gru_units')}\")\n",
    "print(f\"Współczynnik dropout: {best_hps_gru.get('dropout_rate')}\")\n",
    "print(f\"Liczba jednostek Dense: {best_hps_gru.get('dense_units')}\")\n",
    "# print(f\"Learning rate: {best_hps_gru.get('learning_rate')}\")\n",
    "# print(f\"Batch size: {best_hps_gru.get('batch_size')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 17ms/step - accuracy: 0.7875 - f1_m: 15.6929 - loss: 0.4453 - precision_m: 15.8917 - recall_m: 15.8073 - val_accuracy: 0.8184 - val_f1_m: 16.1621 - val_loss: 0.3980 - val_precision_m: 16.0506 - val_recall_m: 16.4591\n",
      "Epoch 2/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 17ms/step - accuracy: 0.8259 - f1_m: 15.8365 - loss: 0.3853 - precision_m: 15.9868 - recall_m: 15.8744 - val_accuracy: 0.8213 - val_f1_m: 15.8037 - val_loss: 0.3934 - val_precision_m: 16.0506 - val_recall_m: 15.7438\n",
      "Epoch 3/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 20ms/step - accuracy: 0.8339 - f1_m: 15.8664 - loss: 0.3712 - precision_m: 15.9897 - recall_m: 15.9160 - val_accuracy: 0.8208 - val_f1_m: 15.8168 - val_loss: 0.3933 - val_precision_m: 16.0506 - val_recall_m: 15.7675\n",
      "Epoch 4/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 21ms/step - accuracy: 0.8394 - f1_m: 15.8277 - loss: 0.3612 - precision_m: 15.9827 - recall_m: 15.8414 - val_accuracy: 0.8197 - val_f1_m: 15.6049 - val_loss: 0.3967 - val_precision_m: 16.0506 - val_recall_m: 15.3629\n",
      "Epoch 5/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m971s\u001b[0m 24ms/step - accuracy: 0.8426 - f1_m: 15.8602 - loss: 0.3550 - precision_m: 16.0070 - recall_m: 15.8760 - val_accuracy: 0.8200 - val_f1_m: 15.9818 - val_loss: 0.3988 - val_precision_m: 16.0506 - val_recall_m: 16.0986\n",
      "Epoch 6/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 18ms/step - accuracy: 0.8447 - f1_m: 15.8998 - loss: 0.3515 - precision_m: 16.0114 - recall_m: 15.9511 - val_accuracy: 0.8194 - val_f1_m: 15.8953 - val_loss: 0.3975 - val_precision_m: 16.0506 - val_recall_m: 15.9256\n",
      "Epoch 7/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 19ms/step - accuracy: 0.8467 - f1_m: 15.8344 - loss: 0.3483 - precision_m: 15.9868 - recall_m: 15.8447 - val_accuracy: 0.8190 - val_f1_m: 15.9452 - val_loss: 0.3990 - val_precision_m: 16.0506 - val_recall_m: 16.0231\n",
      "Epoch 8/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 20ms/step - accuracy: 0.8470 - f1_m: 15.8163 - loss: 0.3465 - precision_m: 15.9693 - recall_m: 15.8237 - val_accuracy: 0.8177 - val_f1_m: 15.9319 - val_loss: 0.4015 - val_precision_m: 16.0506 - val_recall_m: 16.0009\n",
      "Epoch 9/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 15ms/step - accuracy: 0.8486 - f1_m: 15.8424 - loss: 0.3450 - precision_m: 15.9888 - recall_m: 15.8543 - val_accuracy: 0.8171 - val_f1_m: 16.0498 - val_loss: 0.4027 - val_precision_m: 16.0506 - val_recall_m: 16.2386\n",
      "Epoch 10/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 15ms/step - accuracy: 0.8471 - f1_m: 15.8864 - loss: 0.3465 - precision_m: 15.9875 - recall_m: 15.9432 - val_accuracy: 0.8169 - val_f1_m: 15.8526 - val_loss: 0.4053 - val_precision_m: 16.0506 - val_recall_m: 15.8437\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.8165 - f1_m: 15.8432 - loss: 0.4059 - precision_m: 16.0262 - recall_m: 15.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss, Accuracy: [0.4052841067314148, 0.8169156312942505, 15.852566719055176, 16.050600051879883, 15.843700408935547]\n"
     ]
    }
   ],
   "source": [
    "# Trenowanie najlepszego modelu GRU\n",
    "best_model_gru = tuner_gru.hypermodel.build(best_hps)\n",
    "history_gru = best_model_gru.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=best_hps.get('batch_size')  # Najlepszy batch size\n",
    ")\n",
    "\n",
    "# Ewaluacja\n",
    "results_gru = best_model_gru.evaluate(X_val, y_val)\n",
    "print(\"Final Loss, Accuracy:\", results_gru)\n",
    "\n",
    "# Zapis najlepszego modelu\n",
    "best_model_gru.save(\"models/best_gru_sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1280000, 20)\n",
      "y_train shape: (1280000,)\n",
      "X_val shape: (320000, 20)\n",
      "y_val shape: (320000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuner_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Trenowanie najlepszego modelu CNN\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_model_cnn \u001b[38;5;241m=\u001b[39m tuner_cnn\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hps)\n\u001b[1;32m      3\u001b[0m history_cnn \u001b[38;5;241m=\u001b[39m best_model_cnn\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      4\u001b[0m     X_train, y_train,\n\u001b[1;32m      5\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[1;32m      6\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m \u001b[38;5;66;03m#best_hps.get('batch_size')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ewaluacja\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuner_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "# Trenowanie najlepszego modelu CNN\n",
    "best_model_cnn = tuner_cnn.hypermodel.build(best_hps)\n",
    "history_cnn = best_model_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32 #best_hps.get('batch_size')\n",
    ")\n",
    "\n",
    "# Ewaluacja\n",
    "results_cnn = best_model_cnn.evaluate(X_val, y_val)\n",
    "print(\"Final Loss, Accuracy:\", results_cnn)\n",
    "\n",
    "# Zapis modelu\n",
    "best_model_cnn.save(\"models/best_cnn_sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 15ms/step - accuracy: 0.7885 - loss: 0.4486 - val_accuracy: 0.8183 - val_loss: 0.3981\n",
      "Epoch 2/10\n",
      "\u001b[1m40000/40000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 15ms/step - accuracy: 0.8252 - loss: 0.3862 - val_accuracy: 0.8196 - val_loss: 0.3954\n",
      "Epoch 3/10\n",
      "\u001b[1m14547/40000\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:28\u001b[0m 15ms/step - accuracy: 0.8366 - loss: 0.3663"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Trenowanie najlepszego modelu lstm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hps)\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      4\u001b[0m     X_train, y_train,\n\u001b[1;32m      5\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[1;32m      6\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m \u001b[38;5;66;03m# best_hps.get('batch_size')  # Wybór batch_size z hiperparametrów\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ewaluacja\u001b[39;00m\n\u001b[1;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mevaluate(X_val, y_val)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Trenowanie najlepszego modelu lstm\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32 # best_hps.get('batch_size')  # Wybór batch_size z hiperparametrów\n",
    ")\n",
    "\n",
    "# Ewaluacja\n",
    "results = best_model.evaluate(X_val, y_val)\n",
    "print(\"Final Loss, Accuracy:\", results)\n",
    "\n",
    "# Zapis modelu\n",
    "best_model.save(\"models/best_lstm_sentiment_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
